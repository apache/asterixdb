#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Error code:
# 0 --- 999:  runtime errors
# 1000 ---- 1999: compilation errors
# 2000 ---- 2999: storage errors
# 3000 ---- 3999: feed errors
# 4000 ---- 4999: lifecycle management errors

# For the extension lifecycle
4001 = Two Extensions share the same Id: %1$s
4002 = Extension Conflict between %1$s and %2$s both extensions extend %3$s
4003 = Unsupported message type: %1$s
4004 = Invalid configuration: %1$s
4005 = Unsupported replication strategy %1$s

# Type errors
1 = Field type %1$s cannot be promoted to type %2$s
2,1002 = Type mismatch: function %1$s expects its %2$s input parameter to be of type %3$s, but the actual input type is %4$s
3,1003 = Type incompatibility: function %1$s gets incompatible input values: %2$s and %3$s
4,1004 = Unsupported type: %1$s cannot process input type %2$s
5,1005 = Invalid item type: function %1$s cannot process item type %2$s in an input array (or multiset)
13,1006 = Duplicate field name \"%1$s\"
1009 = A returning expression cannot contain dataset access
37,1091 = Type mismatch: expected value of type %1$s, but got the value of type %2$s
51 = Incomparable input types: %1$s and %2$s

# Data errors
6 = Invalid format for %1$s in %2$s
7 = Overflow in %1$s
8 = Underflow in %1$s
9 = Injected failure in %1$s
10 = Invalid value: function %1$s expects its %2$s input parameter to be a non-negative value, got %3$s
11 = Index out of bound in %1$s: %2$s
12 = Invalid implicit scalar to collection coercion in %1$s
14 = Property %1$s not set
15 = Storage metadata directory of %1$s in %2$s already exists
16 = Storage metadata directory of %1$s in %2$s could not be created
17 = Unknown external file pending operation %1$s
18 = Cannot convert the %1$s type to the %2$s type.
19 = Cannot convert integer types. The source type should be one of %1$s.
20 = Cannot convert integer types. The target type should be one of %1$s.
21 = Source value %1$s is out of range that %2$s can hold - %2$s.MAX_VALUE: %3$s, %2$s.MIN_VALUE: %4$s
22 = The accessed field is untyped, but should be typed
23 = %1$ss passed before getting back the responses from NCs
24 = Invalid coordinate
25 = Polygon must have at least 3 points
26 = %1$s can not be an instance of polygon
27 = Operation not supported
28 = Invalid duration \"%1$s\"
29 = Unknown duration unit %1$s
30 = Request timed out and will be cancelled
31 = Invalid type-casting math function: %1$s for converting %2$s to %3$s
32 = Cannot execute request, cluster is %1$s
33 = Node is not registered with the CC
35 = Unsupported multiple statements.
36 = Cannot compare non-primitive values
38 = Input contains different list types
39 = Expected integer value, got %1$s
40 = No statement provided
41 = Request %1$s has been cancelled
42 = %1$s: \"%2$s\" is not a TPC-DS table name
43 = Value out of range, function %1$s expects its %2$s input parameter value to be between %3$s and %4$s, received %5$s
44 = %1$s statement is not supported in read-only mode
45 = Invalid value: function %1$s expects its %2$s input parameter to be an integer value, got %3$s
46 = Invalid pattern \"%1$s\" for LIKE
47 = Invalid value for parameter \"%1$s\": %2$s
48 = Unable to process JSON content in request
49 = Parameter(s) %1$s must be specified
50 = Invalid parameter \"%1$s\"
#51 is used

100 = Unsupported JRE: %1$s

200 = External UDF cannot produce expected result. Please check the UDF configuration

# Compile-time check errors
1001 = Syntax error: %1$s
1007 = Invalid expression: function %1$s expects its %2$s input parameter to be a %3$s expression, but the actual expression is %4$s
1008 = Invalid parameter number: function %1$s cannot take %2$s parameters
1010 = Phrase search in Full-text is not yet supported. Only one keyword per expression is permitted
1011 = Unknown dataset type %1$s
1012 = Unknown index type %1$s
1013 = Cannot use %1$s fields as a key for the %2$s index. The index can only support keys of size %3$s
1014 = Field \"%1$s\" is not found
1015 = Index of type %1$s is not supported for dataset \"%2$s\" since it has composite primary keys
1016 = Index of type %1$s is not supported for dataset of type %2$s
1017 = The filter field \"%1$s\" cannot be an optional field
1018 = Field of type %1$s cannot be used as a filter field
1019 = Cannot autogenerate a composite primary key
1020 = Cannot autogenerate a primary key for primary key of type %1$s. Autogenerated primary keys must be of type %2$s
1021 = The primary key field \"%1$s\" cannot be nullable
1022 = Field of type %1$s cannot be used as a primary key field
1023 = Cannot drop dataset %1$s since it is connected to active entity: %2$s
1024 = Identifier %1$s is not found in AQL+ meta-scope
1025 = There is no such join type in AQL+
1026 = The given function expression %1$s cannot utilize index
1027 = Dataset of type %1$s does not have a primary index
1028 = Query parameter %1$s is not supported
1029 = No metadata exists for dataset %1$s
1030 = The subtree does not have any data source
1031 = The subtree does not have any additional data source
1032 = Could not match the given optimizable function expression to any index field name
1033 = Only strings, ordered and unordered list types are supported
1034 = Tokenizer is not applicable to the given index kind %1$s
1035 = Incompatible search modifier %1$s for index type %2$s
1036 = Unknown search modifier type %1$s
1037 = Invalid query parameter %1$s -- value has to be greater than or equal to %2$s %3$s
1038 = Illegal state. %1$s
1039 = Two-phase locking violation -- locks can not be acquired after unlocking
1040 = Dataset id space is exhausted
1041 = Cannot create enforced index on \"%1$s\" field with non-optional type
1042 = Cannot create non-enforced typed index of this kind: %1$s
1043 = Cannot use %1$s fields as key for the R-tree index. There can be only one field as a key for the R-tree index.
1044 = Communication-related exception occurred during the execution of a remote method call
1045 = Illegal attempt to upgrade metadata lock from %1$s to %2$s
1046 = Illegal attempt to downgrade metadata lock from %1$s to %2$s
1047 = Metadata lock cannot be upgraded! because it was not acquired before
1048 = Metadata lock cannot be downgraded! because it was not acquired before
1049 = Metadata lock cannot be acquired for %1$s since it is already acquired for %2$s
1050 = Cannot find dataset with name %1$s in dataverse %2$s
1051 = Cannot create enforced index on \"%1$s\" field. The field is closed type.
1052 = Cannot create index with the same field \"%1$s\" specified more than once.
1053 = Cannot create primary index on external dataset.
1054 = Compilation failed due to some problem in the query plan.
1055 = Incompatible function language: %1$s.
1056 = Too many options were specified for %1$s
1057 = Expression of type %1$s is not supported in constant record
1058 = Literal of type %1$s is not supported in constant record
1059 = Field(s) %1$s unsupported in the with clause
1060 = Field \"%1$s\" in the with clause must be of type %2$s, but found %3$s
1061 = Field \"%1$s\" in the with clause cannot be null or missing
1062 = Configuration parameter cannot be of type %1$s
1063 = Cannot find dataverse with name %1$s
1064 = An error was occurred while converting type %1$s to type %2$s.
1065 = There should be at least two applicable indexes.
1066 = Cannot serialize a value.
1067 = Cannot find a non-missing SELECT operator in GROUP operator for a left-outer-join plan optimization.
1068 = Cannot get the conditional split variable for the given UNNESTMAP operator.
1069 = Cannot drop index \"%1$s\". Drop dataset \"%1$s\" to remove this index
1070 = Metadata error. %1$s
1071 = A dataverse with this name %1$s already exists.
1072 = A dataset with name %1$s already exists in dataverse %2$s
1073 = Cannot resolve alias reference for undefined identifier %1$s
1074 = Cannot resolve ambiguous alias reference for identifier %1$s
1075 = Inside limit clauses, it is disallowed to reference a variable having the same name as any variable bound in the same scope as the limit clause.
1076 = Cannot find dataset %1$s because there is no dataverse declared, nor an alias with name %1$s!
1077 = Cannot find dataset %1$s in dataverse %2$s nor an alias with name %1$s!
1078 = Unexpected operator %1$s in an OperatorExpr starting with %2$s
1079 = Compilation error: %1$s
1080 = Cannot find node group with name %1$s
1081 = Cannot find function with name %1$s
1082 = Cannot find datatype with name %1$s
1083 = Cannot find index with name %1$s
1084 = An index with this name %1$s already exists
1085 = A datatype with this name %1$s already exists
1086 = No value for parameter: %1$s
1087 = Invalid number of arguments for function %1$s
1088 = Required field %1$s was not found
1089 = Field %1$s must be of type %2$s but found to be of type %3$s
1090 = Field %1$s must be of an array of type %2$s but found to contain an item of type %3$s
1092 = Parameter %1$s cannot be set
1093 = A parser error has occurred. The detail exception: %1$s
1094 = Cannot parse range map: %1$s
1095 = Expected function call
1096 = Unknown compression scheme %1$s. Supported schemes are %2$s
1097 = Subfield(s) %1$s in \"%2$s\" unsupported in the with clause
1098 = Invalid window frame definition
1099 = Unexpected window frame definition
1100 = Unexpected window expression
1101 = Unexpected ORDER BY clause in window expression
1102 = Expected window or aggregate function, got: %1$s
1103 = Illegal use of identifier: %1$s
1104 = Invalid modifier %1$s for function %2$s
1105 = Operation not supported on primary index %1$s
1106 = Expected constant value
1107 = Unexpected hint: %1$s. %2$s expected at this location
1108 = External source error. %1$s
1109 = External source container %1$s not found
1110 = The parameters \"%1$s\" and \"%2$s\" cannot be provided at the same time
1111 = Property \"%1$s\" expects value(s) of type %2$s
1112 = Invalid format for property \"%1$s\"
1113 = Invalid pattern %1$s
1114 = The provided external dataset configuration returned no files from the external source
1115 = A synonym with this name %1$s already exists
1116 = Cannot find synonym with name %1$s
1117 = Unknown library %1$s
1118 = Too many grouping sets in group by clause: %1$s. Maximum allowed: %2$s.
1119 = Invalid argument to grouping() function
1120 = Unexpected alias: %1$s
1121 = Illegal use of aggregate FILTER clause
1122 = Error compiling function %1$s. %2$s

# Feed Errors
3001 = Illegal state.
3002 = Tuple is too large for a frame
3003 = Unknown tuple forward policy
3004 = Unable to create adapter as class loader not configured for library %1$s in dataverse %2$s
3005 = At record: %1$s - Field %2$s is not privatean optional type so it cannot accept null value
3006 = Illegal field %1$s in closed type %2$s
3007 = Twitter4J library not found!
3008 = Unable to ingest data
3009 = Exception in get record type %1$s for feed
3010 = Does not support Hive data with list of non-primitive types
3011 = Cannot get hive type for field of type %1$s
3012 = Failed to get columns of record
3013 = Cannot deserialize Hive records with no closed columns
3014 = Non-optional UNION type is not supported.
3015 = Failed to get the type information for field %1$s
3016 = Cannot parse null field
3017 = Cannot parse hive list with null values
3018 = Field %1$s of meta record is not an optional type so it cannot accept null value
3019 = Cannot get PK from record part
3020 = This operation cannot be done when Feed %1$s is alive
3021 = Malformed input stream
3022 = Unknown data source type: %1$s
3023 = Unknown input stream factory: %1$s
3024 = Failed to create stream factory
3025 = Unknown record reader factory: %1$s
3026 = Unknown format: %1$s
3027 = Unknown record format for a record with meta parser. Did you specify the parameter %1$s
3028 = Field already defined in %1$s part
3029 = Unknown field: %1$s
3031 = No node controllers found at the address: %1$s
3032 = Unable to resolve hostname '%1$s' to an IP address
3033 = Unknown DCP request: %1$s
3034 = Attempt to register to a failed feed data provider
3035 = Feed already has an intake job
3036 = Feed job already registered in intake jobs
3037 = Feed job already registered in all jobs
3038 = Record is too large. Maximum record size is %1$s
3039 = Cannot parse list item of type %1$s
3040 = Argument type: %1$s
3041 = Unable to load/instantiate class %1$s
3042 = UDF of kind %1$s not supported
3043 = Unknown function kind %1$s
3044 = Library class loader already registered!
3045 = Cannot handle a function argument of type %1$s
3046 = Object of type %1$s not supported
3047 = External %1$s not supported
3048 = Invalid feed runtime: %1$s
3049 = '%1$s' is not a valid delimiter. The length of a delimiter should be 1
3050 = '%1$s' is not a valid %2$s. The length of %2$s should be 1
3051 = Quote '%1$s' cannot be used with the delimiter '%2$s'
3052 = Was not able to find a file in the files index
3053 = Field %1$s can not be null
3054 = Mismatch Type, expecting a value of type %1$s
3055 = Unexpected ADM token kind: %1$s
3056 = Illegal escape '\%1$s'
3057 = Found END_RECORD while expecting a record field.
3058 = This record is closed, you can not add extra fields! new field name: %1$s
3059 = Unexpected ADM token kind: %1$s while expecting ":"
3060 = Found COMMA %1$s %2$s record field
3061 = Unsupported interval type: %1$s
3062 = Interval was not closed
3063 = The interval start and end point types do not match: %1$s != %2$s
3064 = Missing COMMA before interval end point
3065 = This can not be an instance of interval: missing T for a datetime value
3066 = Unsupported interval type: %1$s
3067 = Interval argument not properly constructed
3068 = Found END_COLLECTION while expecting a list item
3069 = Found COMMA before any list item
3070 = Found COMMA while expecting a list item
3071 = Found END_RECORD while expecting a list item
3072 = Cannot cast the %1$s type to the %2$s type
3073 = Missing deserializer method for constructor: %1$s
3074 = %1$s cannot be an instance of %2$s
3075 = Closed field %1$s has null value
3076 = %1$s: no files found
3077 = %1$s: path not found
3078 = Cannot obtain hdfs scheduler
3079 = Cannot register runtime, active manager has been shutdown
3080 = Unexpected feed datatype '%1$s'
3081 = socket is not properly configured
3082 = Invalid %1$s %2$s as it is not part of the AsterixDB cluster. Valid choices are %3$s
3083 = Duplicate feed adaptor name: %1$s
3084 = Cannot subscribe to events of a failed active entity
3085 = Unknown Adapter Name.
3086 = Cannot find record reader %1$s with specified configuration
3087 = Cannot find function %1$s
3088 = %1$s is not a valid runtime Id
3089 = %1$s is already started and has state %2$s
3090 = %1$s cannot be stopped because its state is %2$s
3091 = Cannot add dataset to %1$s because its state is %2$s
3092 = Cannot remove dataset from %1$s because its state is %2$s
3093 = %1$s is already registered
3094 = Cannot create index on dataset %1$s because it is connected to %2$s with state %3$s
3095 = Cannot drop index of dataset %1$s because it is connected to %2$s with state %3$s
3096 = Active Notification Handler is suspended
3097 = Active Entity %1$s has not been registered
3098 = Cannot deregister %1$s because it is active
3099 = Attempt to initialize an initialized Active Notification Handler
3101 = Recovery request while recovery is currently ongoing
3102 = Unreported exception causing task failure
3103 = %1$s is already suspended and has state %2$s
3104 = %1$s cannot be resumed from state %2$s
3105 = %1$s is already registered
3106 = %1$s is not registered
3107 = Active Notification Handler is already suspended
3110 = Feed failed while reading a new record
3111 = Feed %1$s is not connected to any dataset
3112 = Array/Multiset item cannot be null
3113 = Failed to parse record
3114 = Failed to parse record content
3115 = Failed to parse record metadata
3116 = Failed to decode input
3117 = Failed to parse record, malformed log record

# Lifecycle management errors
4000 = Partition id %1$s for node %2$s already in use by node %3$s
4006 = Not all node controllers required for request execution have joined the cluster. Nodes %1$s appear missing, double check the logs on these machines and the cluster configuration
