#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Error code:
# 0 --- 999:  runtime errors
# 1000 ---- 1999: compilation errors
# 2000 ---- 2999: storage errors
# 3000 ---- 3999: feed errors
# 4000 ---- 4999: lifecycle management errors

# For the extension lifecycle
4001 = Two Extensions share the same Id: %1$s
4002 = Extension Conflict between %1$s and %2$s both extensions extend %3$s
4003 = Unsupported message type: %1$s
4004 = Invalid configuration: %1$s
4005 = Unsupported replication strategy %1$s

# Type errors
2,1002 = Type mismatch: function %1$s expects its %2$s input parameter to be type %3$s, but the actual input type is %4$s
3,1003 = Type incompatibility: function %1$s gets incompatible input values: %2$s and %3$s
4,1004 = Unsupported type: %1$s cannot process input type %2$s
5,1005 = Invalid item type: function %1$s cannot process item type %2$s in an input array (or multiset)
13,1006 = Duplicate field name \"%1$s\"
1009 = A returning expression cannot contain dataset access

# Data errors
6 = Invalid format for %1$s in %2$s
7 = Overflow happend in %1$s
8 = Underflow happend in %1$s
9 = Injected failure in %1$s
10 = Invalid value: function %1$s expects its %2$s input parameter to be a non-negative value, but gets %3$s
11 = Index out of bound in %1$s: %2$s
12 = Invalid implicit scalar to collection coercion in %1$s
14 = Property %1$s not set
15 = Storage metadata directory of %1$s in %2$s already exists
16 = Storage metadata directory of %1$s in %2$s couldn't be created
17 = Unknown external file pending operation %1$s
18 = Cannot convert the %1$s type to the %2$s type.
19 = Cannot convert integer types. The source type should be one of %1$s.
20 = Cannot convert integer types. The target type should be one of %1$s.
21 = Source value %1$s is out of range that %2$s can hold - %2$s.MAX_VALUE: %3$s, %2$s.MIN_VALUE: %4$s
22 = The accessed field is untyped, but should be typed
23 = %1$ss passed before getting back the responses from NCs
24 = Invalid coordinate
25 = Polygon must have at least 3 points
26 = %1$s can not be an instance of polygon

100 = Unable to instantiate class %1$s

# Compile-time check errors
1007 = Invalid expression: function %1$s expects its %2$s input parameter to be a %3$s expression, but the actual expression is %4$s
1008 = Invalid parameter number: function %1$s cannot take %2$s parameters
1010 = Phrase search in Full-text is not yet supported. Only one keyword per expression is permitted
1011 = Unknown dataset type %1$s
1012 = Unknown index type %1$s
1013 = Cannot use %1$s fields as a key for the %2$s index. The index can only support keys of size %3$s
1014 = Field \"%1$s\" is not found
1015 = Index of type %1$s is not supported for dataset \"%2$s\" since it has composite primary keys
1016 = Index of type %1$s is not supported for dataset of type %2$s
1017 = The filter field \"%1$s\" cannot be an optional field
1018 = Field of type %1$s cannot be used as a filter field
1019 = Cannot autogenerate a composite primary key
1020 = Cannot autogenerate a primary key for primary key of type %1$s. Autogenerated primary keys must be of type %2$s
1021 = The primary key field \"%1$s\" cannot be nullable
1022 = Field of type %1$s cannot be used as a primary key field
1023 = Cannot drop dataset %1$s since it is connected to active entity: %2$s
1024 = Identifier %1$s is not found in AQL+ meta-scope
1025 = There is no such join type in AQL+
1026 = The given function expression %1$s cannot utilize index
1027 = Dataset of type %1$s doesn't have a primary index
1028 = Query parameter %1$s is not supported
1029 = No metadata exists for dataset %1$s
1030 = The subtree does not have any data source
1031 = The subtree does not have any additional data source
1032 = Could not match the given optimizable function expression to any index field name
1033 = Only strings, ordered and unordered list types are supported
1034 = Tokenizer is not applicable to the given index kind %1$s
1035 = Incompatible search modifier %1$s for index type %2$s
1036 = Unknown search modifier type %1$s
1037 = Invalid query parameter %1$s -- value has to be greater than or equal to %2$s bytes
1038 = Illegal state. %1$s
1039 = Two-phase locking violation -- locks can not be acquired after unlocking
1040 = Dataset id space is exhausted
1041 = Cannot create enforced index on \"%1$s\" field with non-optional type
1042 = Cannot create non-enforced typed index of this kind: %1$s

# Feed Errors
3001 = Illegal state.
3002 = Tuple is too large for a frame
3003 = Unknown tuple forward policy
3004 = Unable to create adapter as class loader not configured for library %1$s in dataverse %2$s
3005 = At record: %1$s - Field %2$s is not privatean optional type so it cannot accept null value
3006 = Illegal field %1$s in closed type %2$s
3007 = Twitter4J library not found!
3008 = Unable to ingest data
3009 = Exception in get record type %1$s for feed
3010 = Doesn't support Hive data with list of non-primitive types
3011 = Cannot get hive type for field of type %1$s
3012 = Failed to get columns of record
3013 = Cannot deserialize Hive records with no closed columns
3014 = Non-optional UNION type is not supported.
3015 = Failed to get the type information for field %1$s
3016 = Cannot parse null field
3017 = Cannot parse hive list with null values
3018 = Field %1$s of meta record is not an optional type so it cannot accept null value
3019 = Cannot get PK from record part
3020 = This operation cannot be done when Feed %1$s is alive
3021 = Malformed input stream
3022 = Unknown data source type: %1$s
3023 = Unknown input stream factory: %1$s
3024 = Failed to create stream factory
3025 = Unknown record reader factory: %1$s
3026 = Unknown format: %1$s
3027 = Unknown record format for a record with meta parser. Did you specify the parameter %1$s
3028 = Field already defined in %1$s part
3029 = Unknown field: %1$s
3031 = No node controllers found at the address: %1$s
3032 = Unable to resolve hostname '%1$s' to an IP address
3033 = Unknown DCP request: %1$s
3034 = Attempt to register to a failed feed data provider
3035 = Feed already has an intake job
3036 = Feed job already registered in intake jobs
3037 = Feed job already registered in all jobs
3038 = Record is too large!. Maximum record size is %1$s
3039 = Cannot parse list item of type %1$s
3040 = Argument type: %1$s
3041 = Unable to load/instantiate class %1$s
3042 = UDF of kind %1$s not supported
3043 = Unknown function kind %1$s
3044 = Library class loader already registered!
3045 = Cannot handle a function argument of type %1$s
3046 = Object of type %1$s not supported
3047 = External %1$s not supported
3048 = Invalid feed runtime: %1$s
3049 = '%1$s' is not a valid delimiter. The length of a delimiter should be 1
3050 = '%1$s' is not a valid quote. The length of a quote should be 1
3051 = Quote '%1$s' cannot be used with the delimiter '%2$s'
3052 = Was not able to find a file in the files index
3053 = Field %1$s can not be null
3054 = Mismatch Type, expecting a value of type %1$s
3055 = Unexpected ADM token kind: %1$s
3056 = Illegal escape '\%1$s'
3057 = Found END_RECORD while expecting a record field.
3058 = This record is closed, you can not add extra fields! new field name: %1$s
3059 = Unexpected ADM token kind: %1$s while expecting ":"
3060 = Found COMMA %1$s %2$s record field
3061 = Unsupported interval type: %1$s
3062 = Interval was not closed
3063 = The interval start and end point types do not match: %1$s != %2$s
3064 = Missing COMMA before interval end point
3065 = This can not be an instance of interval: missing T for a datetime value
3066 = Unsupported interval type: %1$s
3067 = Interval argument not properly constructed
3068 = Found END_COLLECTION while expecting a list item
3069 = Found COMMA before any list item
3070 = Found COMMA while expecting a list item
3071 = Found END_RECORD while expecting a list item
3072 = Cannot cast the %1$s type to the %2$s type
3073 = Missing deserializer method for constructor: %1$s
3074 = This can not be an instance of %1$s
3075 = Closed field %1$s has null value
3076 = %1$s: no files found
3077 = %1$s: path not found
3078 = Cannot obtain hdfs scheduler
3079 = Cannot register runtime, active manager has been shutdown
3080 = Unexpected feed datatype '%1$s'
3081 = socket is not properly configured
3082 = Invalid %1$s %2$s as it is not part of the AsterixDB cluster. Valid choices are %3$s
3083 = Duplicate feed adaptor name: %1$s
3084 = Cannot subscribe to events of a failed active entity
3085 = Unknown Adapter Name.
3086 = Cannot find record reader %1$s with specified configuration
3087 = Cannot find function %1$s
3088 = %1$s is not a valid runtime Id

# Lifecycle management errors
4000 = Partition id %1$d for node %2$s already in use by node %3$s
