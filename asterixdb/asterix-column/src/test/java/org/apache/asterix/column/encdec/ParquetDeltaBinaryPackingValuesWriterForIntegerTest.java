/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.asterix.column.encdec;

import java.io.ByteArrayOutputStream;
import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Queue;
import java.util.Random;

import org.apache.asterix.column.bytes.decoder.ParquetDeltaBinaryPackingValuesReader;
import org.apache.asterix.column.bytes.encoder.ParquetDeltaBinaryPackingValuesWriterForInteger;
import org.apache.asterix.column.bytes.stream.in.ByteBufferInputStream;
import org.apache.asterix.column.common.buffer.DummyBufferCache;
import org.apache.asterix.column.common.buffer.TestWriteMultiPageOp;
import org.apache.commons.lang3.mutable.Mutable;
import org.apache.commons.lang3.mutable.MutableObject;
import org.apache.hyracks.storage.am.lsm.btree.column.api.IColumnBufferProvider;
import org.apache.hyracks.storage.am.lsm.btree.column.api.IColumnWriteMultiPageOp;
import org.apache.parquet.bytes.BytesInput;
import org.apache.parquet.io.ParquetDecodingException;
import org.junit.Assert;
import org.junit.Test;

/**
 * Generated by: LLM
 */
public class ParquetDeltaBinaryPackingValuesWriterForIntegerTest {
    private static final int PAGE_SIZE = 256 * 1024;

    @Test
    public void testEmptyPageRoundTrip() throws Exception {
        // Not a typical production case (writers usually know the tuple count),
        // but we still want deterministic behavior and no crashes.
        int[] values = new int[0];
        assertRoundTrip(values);
    }

    @Test
    public void testSingleValueRoundTripAndReadBeyondThrows() throws Exception {
        int[] values = new int[] { 42 };
        assertRoundTrip(values);
    }

    @Test
    public void testConstantValuesWithPaddingAndZeroBitWidth() throws Exception {
        // Ensure: deltas are always 0 -> bit width can be 0, and tuple count isn't aligned to miniblock size (32).
        int[] values = new int[35];
        for (int i = 0; i < values.length; i++) {
            values[i] = 7;
        }
        assertRoundTrip(values);
    }

    @Test
    public void testOverflowDeltasRoundTrip() throws Exception {
        // Forces delta overflow cases (int modular arithmetic), which this writer explicitly claims to handle.
        int[] values = new int[] { Integer.MAX_VALUE, Integer.MIN_VALUE, 0, -1, Integer.MAX_VALUE, Integer.MIN_VALUE };
        assertRoundTrip(values);
    }

    @Test
    public void testRandomValuesRoundTripAcrossMultipleBlocks() throws Exception {
        // Default block size is 128, so this crosses multiple blocks and triggers internal flushes.
        Random rnd = new Random(0xC0FFEE);
        int[] values = new int[2048];
        for (int i = 0; i < values.length; i++) {
            values[i] = rnd.nextInt();
        }
        assertRoundTrip(values);
    }

    @Test
    public void testExactMiniBlockAndBlockBoundaries() throws Exception {
        // Mini block size is 32 (DEFAULT_NUM_BLOCK_VALUES=128, DEFAULT_NUM_MINIBLOCKS=4).
        assertRoundTrip(increasingSequence(32));
        assertRoundTrip(increasingSequence(128));
        // Crosses exactly into the next block and requires block flush + new block header.
        assertRoundTrip(increasingSequence(129));
    }

    @Test
    public void testBitWidthSwingWithinBlock() throws Exception {
        // Small deltas for a while, then a huge delta to force a larger bit width.
        int[] values = new int[96];
        values[0] = 0;
        for (int i = 1; i < 64; i++) {
            values[i] = values[i - 1] + 1;
        }
        // Force a big jump but without int overflow.
        values[64] = Integer.MAX_VALUE / 2;
        for (int i = 65; i < values.length; i++) {
            values[i] = values[i - 1] + 1;
        }
        assertRoundTrip(values);
    }

    @Test
    public void testTruncatedPageFailsFast() throws Exception {
        int[] values = increasingSequence(256);
        WriterAndReaderFactory factory = new WriterAndReaderFactory();
        ParquetDeltaBinaryPackingValuesWriterForInteger writer = factory.createWriter();
        for (int v : values) {
            writer.writeInteger(v);
        }
        byte[] page = toByteArray(writer.getBytes());

        // Truncate at multiple points (including some inside the delta blocks).
        // Expect initFromPage() or subsequent reads to fail.
        for (int cut = 0; cut < page.length; cut += Math.max(1, page.length / 25)) {
            byte[] truncated = Arrays.copyOf(page, cut);
            assertCorruptPageDoesNotRoundTrip(truncated, values, 512);
        }
    }

    @Test
    public void testBodyBitFlipCorruptionDoesNotSilentlyRoundTrip() throws Exception {
        // Important: only corrupt bytes after the header (config/count/firstValue) to avoid
        // pathological allocations from a corrupted config.
        int[] values = new int[512];
        Random rnd = new Random(0xBADC0DE);
        values[0] = rnd.nextInt();
        for (int i = 1; i < values.length; i++) {
            // Use small deltas to keep encoding compact and deterministic
            values[i] = values[i - 1] + (rnd.nextInt(5) - 2);
        }

        WriterAndReaderFactory factory = new WriterAndReaderFactory();
        ParquetDeltaBinaryPackingValuesWriterForInteger writer = factory.createWriter();
        for (int v : values) {
            writer.writeInteger(v);
        }
        byte[] page = toByteArray(writer.getBytes());
        int headerLen = headerLength(page);

        // Flip random bits in the body and ensure we either throw or don't decode back to the same values.
        for (int i = 0; i < 200; i++) {
            byte[] mutated = Arrays.copyOf(page, page.length);
            // Corrupt close to the start of the body to avoid flipping bytes that only affect padded/unread values.
            int start = Math.min(headerLen, mutated.length - 1);
            int endExclusive = Math.min(mutated.length, headerLen + 128);
            if (endExclusive <= start) {
                endExclusive = mutated.length;
            }
            int idx = start + rnd.nextInt(Math.max(1, endExclusive - start));
            mutated[idx] ^= (byte) (1 << (rnd.nextInt(8)));
            assertCorruptPageDoesNotRoundTrip(mutated, values, 2048);
        }
    }

    @Test
    public void testResetProducesIndependentPages() throws Exception {
        WriterAndReaderFactory factory = new WriterAndReaderFactory();
        ParquetDeltaBinaryPackingValuesWriterForInteger writer = factory.createWriter();

        int[] first = new int[] { -10, -9, -8, -7, -7, -7, 0, 3, 10 };
        for (int v : first) {
            writer.writeInteger(v);
        }
        byte[] firstPage = toByteArray(writer.getBytes());

        writer.reset();

        int[] second = new int[] { 100, 50, 25, 0, -25, -50, -100 };
        for (int v : second) {
            writer.writeInteger(v);
        }
        byte[] secondPage = toByteArray(writer.getBytes());

        Assert.assertArrayEquals(first, decodePageExactly(firstPage, first.length));
        Assert.assertArrayEquals(second, decodePageExactly(secondPage, second.length));
    }

    private static void assertRoundTrip(int[] values) throws Exception {
        WriterAndReaderFactory factory = new WriterAndReaderFactory();
        ParquetDeltaBinaryPackingValuesWriterForInteger writer = factory.createWriter();
        for (int v : values) {
            writer.writeInteger(v);
        }

        byte[] page = toByteArray(writer.getBytes());
        Assert.assertArrayEquals(values, decodePageExactly(page, values.length));
    }

    private static int[] decodePageExactly(byte[] pageBytes, int expectedCount) throws Exception {
        ParquetDeltaBinaryPackingValuesReader reader = new ParquetDeltaBinaryPackingValuesReader();
        ByteBufferInputStream in = new ByteBufferInputStream();
        in.reset(new SingleBufferProvider(ByteBuffer.wrap(pageBytes)));
        reader.initFromPage(in);

        int[] out = new int[expectedCount];
        for (int i = 0; i < expectedCount; i++) {
            out[i] = reader.readInteger();
        }

        // Must throw if we try to read once more.
        try {
            reader.readInteger();
            Assert.fail("Expected ParquetDecodingException when reading beyond totalValueCount");
        } catch (ParquetDecodingException expected) {
            // expected
        }

        return out;
    }

    private static int[] increasingSequence(int length) {
        int[] values = new int[length];
        for (int i = 0; i < length; i++) {
            values[i] = i;
        }
        return values;
    }

    private static byte[] toByteArray(BytesInput bytesInput) throws Exception {
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        bytesInput.writeAllTo(bos);
        return bos.toByteArray();
    }

    private static void assertCorruptPageDoesNotRoundTrip(byte[] corruptedPage, int[] expectedValues, int maxReads)
            throws Exception {
        try {
            int[] decoded = decodePageWithReadLimit(corruptedPage, maxReads);
            // If it didn't throw, it must not silently round-trip to the exact same values.
            Assert.assertFalse("Corrupted page unexpectedly decoded to the original values",
                    Arrays.equals(expectedValues, decoded));
        } catch (Exception e) {
            // Any decoding exception is acceptable. We only want to ensure we don't silently succeed.
        }
    }

    private static int[] decodePageWithReadLimit(byte[] pageBytes, int maxReads) throws Exception {
        ParquetDeltaBinaryPackingValuesReader reader = new ParquetDeltaBinaryPackingValuesReader();
        ByteBufferInputStream in = new ByteBufferInputStream();
        in.reset(new SingleBufferProvider(ByteBuffer.wrap(pageBytes)));
        reader.initFromPage(in);

        int[] out = new int[Math.max(8, Math.min(256, maxReads))];
        int size = 0;
        for (int i = 0; i < maxReads; i++) {
            try {
                int v = reader.readInteger();
                if (size == out.length) {
                    int[] grown = new int[Math.min(maxReads, out.length * 2)];
                    System.arraycopy(out, 0, grown, 0, out.length);
                    out = grown;
                }
                out[size++] = v;
            } catch (ParquetDecodingException e) {
                int[] exact = new int[size];
                System.arraycopy(out, 0, exact, 0, size);
                return exact;
            }
        }
        // If we managed to read maxReads values without an exception, treat it as a failure signal.
        throw new AssertionError("Decoded " + maxReads + " integers from a corrupted page without failing");
    }

    /**
     * Computes the encoded header length: blockSize(varint) + miniBlockNum(varint) + totalValueCount(varint)
     * + firstValue(zigzag varint).
     *
     * <p>
     * This is used to avoid corrupting the config in fuzz tests (which could lead to huge allocations).
     */
    private static int headerLength(byte[] page) throws Exception {
        int p = 0;
        p = skipUnsignedVarInt(page, p);
        p = skipUnsignedVarInt(page, p);
        p = skipUnsignedVarInt(page, p);
        p = skipZigZagVarInt(page, p);
        return p;
    }

    private static int skipUnsignedVarInt(byte[] b, int p) throws Exception {
        // Max 5 bytes for int32 varint.
        for (int i = 0; i < 5; i++) {
            if (p >= b.length) {
                throw new java.io.EOFException();
            }
            int v = b[p++] & 0xFF;
            if ((v & 0x80) == 0) {
                return p;
            }
        }
        throw new IllegalArgumentException("Invalid varint (too long)");
    }

    private static int skipZigZagVarInt(byte[] b, int p) throws Exception {
        // Same encoding width as unsigned varint for int32.
        return skipUnsignedVarInt(b, p);
    }

    private static final class WriterAndReaderFactory {
        private final Mutable<IColumnWriteMultiPageOp> multiPageOpRef;

        private WriterAndReaderFactory() {
            DummyBufferCache dummyBufferCache = new DummyBufferCache(PAGE_SIZE);
            int fileId = dummyBufferCache.createFile();
            this.multiPageOpRef = new MutableObject<>(new TestWriteMultiPageOp(dummyBufferCache, fileId));
        }

        private ParquetDeltaBinaryPackingValuesWriterForInteger createWriter() {
            return new ParquetDeltaBinaryPackingValuesWriterForInteger(multiPageOpRef);
        }
    }

    private static final class SingleBufferProvider implements IColumnBufferProvider {
        private final ByteBuffer buffer;

        private SingleBufferProvider(ByteBuffer buffer) {
            this.buffer = buffer;
        }

        @Override
        public void reset(org.apache.hyracks.storage.am.lsm.btree.column.impls.btree.ColumnBTreeReadLeafFrame frame) {
            throw new UnsupportedOperationException();
        }

        @Override
        public void readAll(Queue<ByteBuffer> buffers) {
            throw new UnsupportedOperationException();
        }

        @Override
        public void releaseAll() {
            throw new UnsupportedOperationException();
        }

        @Override
        public ByteBuffer getBuffer() {
            return buffer;
        }

        @Override
        public int getLength() {
            return buffer.remaining();
        }

        @Override
        public int getColumnIndex() {
            return 0;
        }
    }
}
